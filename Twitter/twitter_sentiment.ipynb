{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9736061e-acd8-482b-b93e-402826461332",
      "cell_type": "code",
      "source": [
        "%pip install -q kagglehub\n",
        "print('done')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9736061e-acd8-482b-b93e-402826461332",
        "outputId": "bdbbfc61-68f6-4720-a1e3-24e725c232d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import sentiment_dataset\n",
        "X, y = sentiment_dataset.load_sentiment_tweets()\n",
        "\n",
        "X = X.sample(n = 20000, random_state=1)\n",
        "y = y.sample(n = 20000, random_state=1)\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMWJA3apR1bu",
        "outputId": "f31c0f15-65e8-44fb-f5e9-4369992823c1"
      },
      "id": "VMWJA3apR1bu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset 'kazanova/sentiment140' from Kaggle...\n",
            "Dataset downloaded to: /kaggle/input/sentiment140\n",
            "Loading data from /kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv...\n",
            "Original dataset shape: (1600000, 6)\n",
            "Shape after filtering out neutral tweets (polarity=2): (1600000, 6)\n",
            "Data processing complete. Returning tweet text and binary sentiment labels.\n",
            "514293     i miss nikki nu nu already  shes always there ...\n",
            "142282     So I had a dream last night. I  remember a sig...\n",
            "403727     @girlyghost ohh poor sickly you   (((hugs)) ho...\n",
            "649503                                  it is raining again \n",
            "610789             @MissKeriBaby wish I was in LA right now \n",
            "                                 ...                        \n",
            "1200592    I get the worst writer's cramp. These thank yo...\n",
            "333050           @ladyinreddress the sun is all gone now... \n",
            "893698     FINALLY a break till Wed, no work OR school, b...\n",
            "1145456                              I want a Blackberry... \n",
            "837125     in montrea doing some much needed ocean swimmi...\n",
            "Name: text, Length: 20000, dtype: object\n",
            "514293     0\n",
            "142282     0\n",
            "403727     0\n",
            "649503     0\n",
            "610789     0\n",
            "          ..\n",
            "1200592    1\n",
            "333050     0\n",
            "893698     1\n",
            "1145456    1\n",
            "837125     1\n",
            "Name: Sentiment, Length: 20000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "id": "e82a9506-206c-4071-9bcc-bc17f56b5d0b",
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "#import dataset\n",
        "#data = pd.read_csv(\"RateMyProfessor_Sample data.csv\", usecols = [\"comments\", \"student_star\"])\n",
        "\n",
        "\n",
        "#preprocessing\n",
        "#remove all punctuation\n",
        "X = X.str.replace(r'[^\\w\\s]+', '', regex = True)\n",
        "#make all letters lowercase\n",
        "X = X.str.lower()\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82a9506-206c-4071-9bcc-bc17f56b5d0b",
        "outputId": "23e265cd-55e7-4bac-a0e6-025f0550d72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "514293     i miss nikki nu nu already  shes always there ...\n",
            "142282     so i had a dream last night i  remember a sign...\n",
            "403727     girlyghost ohh poor sickly you   hugs hope you...\n",
            "649503                                  it is raining again \n",
            "610789              misskeribaby wish i was in la right now \n",
            "                                 ...                        \n",
            "1200592    i get the worst writers cramp these thank you ...\n",
            "333050               ladyinreddress the sun is all gone now \n",
            "893698     finally a break till wed no work or school bot...\n",
            "1145456                                 i want a blackberry \n",
            "837125     in montrea doing some much needed ocean swimmi...\n",
            "Name: text, Length: 20000, dtype: object\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "id": "54675cbf-331c-4420-91ce-cc34e578062b",
      "cell_type": "code",
      "source": [
        "#feature extraction\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#list of stop words\n",
        "stop_str = (['the', 'a', 'and', 'to', 'you', 'is', 'he', 'she', 'of', 'an', 'in',\n",
        "            'but', 'his', 'her', 'was', 'have', 'with', 'take', 'with', 'that', 'do', 'be',\n",
        "            'for', 'if', 'it', 'are', 'on', 'this', 'will', 'at', 'about', 'as', 'so', 'guy',\n",
        "            'him', 'your', 'had', 'can', 'hes', 'from', 'me', 'its', 'shes', 'get', 'my', 'im'])\n",
        "\n",
        "cv = CountVectorizer(stop_words = stop_str)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "\n",
        "#bag of words\n",
        "X_bow = cv.fit_transform(X.values.astype('U'))\n",
        "X_bow.shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54675cbf-331c-4420-91ce-cc34e578062b",
        "outputId": "2f7550f2-59f9-4a08-f49e-de5303996472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 32918)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "id": "9c2f15e8-4676-4cbe-91e8-8b65dd77a477",
      "cell_type": "code",
      "source": [
        "#analysis of dataset\n",
        "#class distribution, text length distribution, total unique words, most common words\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print('The accuracy for Naive Bayes classifier using TF-IDF is {:.5f} on training data'.format(accuracy_score(y_pred = clf.predict(X_train), y_true = y_train)))\n",
        "#pos_ct = sum(data['student_star'] > 0)\n",
        "pos_ct = sum(y > 0)\n",
        "#neg_ct = sum(data['student_star'] < 0)\n",
        "neg_ct = sum(y == 0)\n",
        "\n",
        "print('There are {:.0f} total records.'.format( pos_ct + neg_ct ))\n",
        "print('There are {:.0f} positive records.'.format( pos_ct ))\n",
        "print('There are {:.0f} negative records.'.format( neg_ct ))\n",
        "print('{:.2f}% of records in the dataset are positive.\\n'.format( (pos_ct / (pos_ct + neg_ct)) * 100 ))\n",
        "\n",
        "'''\n",
        "word_ct = pd.read_csv(\"RateMyProfessor_Sample data.csv\", usecols = [\"word_comment\"])\n",
        "plt.hist(word_ct, color='lightgreen', ec='black', bins=10)\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Word Count\")\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "print('\\nThere are {:.0f} unique words.\\n'.format( len(cv.get_feature_names_out()) ))\n",
        "\n",
        "print('The 25 most common words, excluding stop words, are: ')\n",
        "freqs = zip(cv.get_feature_names_out(), X_bow.sum(axis=0).tolist()[0])\n",
        "# sort from largest to smallest\n",
        "print( sorted(freqs, key=lambda x: -x[1]) [:25])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2f15e8-4676-4cbe-91e8-8b65dd77a477",
        "outputId": "204f06e6-cfbf-4f04-d235-f9b66a335c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 20000 total records.\n",
            "There are 10049 positive records.\n",
            "There are 9951 negative records.\n",
            "50.24% of records in the dataset are positive.\n",
            "\n",
            "\n",
            "There are 32918 unique words.\n",
            "\n",
            "The 25 most common words, excluding stop words, are: \n",
            "[('just', 1574), ('not', 1287), ('now', 1203), ('good', 1122), ('up', 1075), ('day', 1005), ('out', 985), ('like', 983), ('all', 961), ('go', 925), ('no', 923), ('dont', 839), ('love', 797), ('got', 772), ('too', 771), ('going', 768), ('cant', 767), ('work', 743), ('today', 725), ('back', 721), ('lol', 704), ('time', 664), ('really', 655), ('what', 652), ('one', 629)]\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "id": "b65ed94f-2062-48e0-99b8-68f5e18fbf74",
      "cell_type": "code",
      "source": [
        "#training classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train-test split with Bag of Words, then apply TF-IDF to have same set of sample data\n",
        "X_bow_train, X_bow_test, y_train, y_test = train_test_split(X_bow, y, test_size = 0.2)\n",
        "\n",
        "y_train_arr = y_train.to_numpy().reshape(-1)\n",
        "\n",
        "X_tfidf_train = tfidf_transformer.fit_transform(X_bow_train)\n",
        "X_tfidf_train.shape\n",
        "X_tfidf_test = tfidf_transformer.fit_transform(X_bow_test)\n",
        "X_tfidf_test.shape\n",
        "\n",
        "print('Classifier\\t Feature Extr.\\t Train Acc.\\t Test Acc.')\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "#naive bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf_bow = MultinomialNB().fit(X_bow_train, y_train_arr)\n",
        "clf_tfidf = MultinomialNB().fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                                              accuracy_score(y_pred = clf_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('Naive Bayes\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                                 accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#support vector machine\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "svm_bow = SGDClassifier().fit(X_bow_train, y_train_arr)\n",
        "svm_tfidf = SGDClassifier().fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM\\t\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                                          accuracy_score(y_pred = svm_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('SVM\\t\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                             accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_bow = LogisticRegression().fit(X_bow_train, y_train_arr)\n",
        "lr_tfidf = LogisticRegression().fit(X_tfidf_train, y_train_arr)\n",
        "print('Log Regression\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('Log Regression\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#linear support vector classification\n",
        "from sklearn.svm import LinearSVC\n",
        "svc_bow = LinearSVC(max_iter = 2000).fit(X_bow_train, y_train_arr)\n",
        "svc_tfidf = LinearSVC().fit(X_tfidf_train, y_train_arr)\n",
        "print('SVC\\t\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = svc_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('SVC\\t\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                  accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b65ed94f-2062-48e0-99b8-68f5e18fbf74",
        "outputId": "34722f13-96af-4f0e-87f7-681294af733f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier\t Feature Extr.\t Train Acc.\t Test Acc.\n",
            "---------------------------------------------------------\n",
            "Naive Bayes\t BoW\t\t 0.91494\t 0.73800\n",
            "Naive Bayes\t TF-IDF\t\t 0.91394\t 0.74100\n",
            "---------------------------------------------------------\n",
            "SVM\t\t BoW\t\t 0.95969\t 0.73850\n",
            "SVM\t\t TF-IDF\t\t 0.88538\t 0.75350\n",
            "---------------------------------------------------------\n",
            "Log Regression\t BoW\t\t 0.93331\t 0.74375\n",
            "Log Regression\t TF-IDF\t\t 0.86675\t 0.75300\n",
            "---------------------------------------------------------\n",
            "SVC\t\t BoW\t\t 0.98931\t 0.72100\n",
            "SVC\t\t TF-IDF\t\t 0.97469\t 0.74475\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "id": "1149fbcb-566c-4e5b-ab30-5273ae03764f",
      "cell_type": "code",
      "source": [
        "#hyperparameter testing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "print('Testing for hyperparameters:')\n",
        "\n",
        "#naive bayes\n",
        "clf_param = {\n",
        "    'fit_prior': (True, False),\n",
        "    'force_alpha': (True, False),\n",
        "    'alpha': (1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1),\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(clf_tfidf, clf_param, cv=5, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes:')\n",
        "for param_name in sorted(clf_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#support vector machine\n",
        "svm_param = {\n",
        "    'max_iter': (1500, 1000, 500),\n",
        "    'loss': ('hinge', 'perceptron', 'squared_error'),\n",
        "    'alpha': (0.01, 0.005, 0.001),\n",
        "}\n",
        "\n",
        "gs_svm = GridSearchCV(svm_tfidf, svm_param, cv=5, n_jobs=-1)\n",
        "gs_svm = gs_svm.fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM:')\n",
        "for param_name in sorted(svm_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#logistic regression\n",
        "lr_param = {\n",
        "    'solver': ('lbfgs', 'liblinear', 'newton-cg'),\n",
        "    'max_iter': (500, 750, 1000, 1250)\n",
        "}\n",
        "\n",
        "gs_lr = GridSearchCV(lr_tfidf, lr_param, cv=5, n_jobs=-1)\n",
        "gs_lr = gs_lr.fit(X_tfidf_train, y_train_arr)\n",
        "print('Logistic Regression:')\n",
        "for param_name in sorted(lr_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#linear support vector classification\n",
        "svc_param = {\n",
        "    'max_iter': (500, 750, 1000, 2000, 2500),\n",
        "    'C': (0.01, 0.1, 0.5, 1.0, 1.5),\n",
        "}\n",
        "\n",
        "gs_svc = GridSearchCV(svc_tfidf, svc_param, cv=5, n_jobs=-1)\n",
        "gs_svc = gs_svc.fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM:')\n",
        "for param_name in sorted(svc_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svc.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1149fbcb-566c-4e5b-ab30-5273ae03764f",
        "outputId": "a8985b78-472d-4e21-858e-1c4ab862c40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for hyperparameters:\n",
            "Naive Bayes:\n",
            "alpha: 1.0\n",
            "fit_prior: True\n",
            "force_alpha: True\n",
            "---------------------------------------------------------\n",
            "SVM:\n",
            "alpha: 0.001\n",
            "loss: 'squared_error'\n",
            "max_iter: 1000\n",
            "---------------------------------------------------------\n",
            "Logistic Regression:\n",
            "max_iter: 500\n",
            "solver: 'liblinear'\n",
            "---------------------------------------------------------\n",
            "SVM:\n",
            "C: 0.1\n",
            "max_iter: 500\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "id": "3d1178ad-934d-4a7d-ba8d-c2555ae958b1",
      "cell_type": "code",
      "source": [
        "#testing the optimized hyperparameters with TF-IDF\n",
        "print('Results of applying tuned hyperparameters')\n",
        "print('-----------------------------------------')\n",
        "\n",
        "print('Classifier\\tTrain Acc.\\tTest Acc.')\n",
        "clf_tfidf = MultinomialNB(alpha = 0.6).fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                                 accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "svm_tfidf = SGDClassifier(alpha = 0.001, loss = 'squared_error', max_iter = 1500).fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                             accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "lr_tfidf = LogisticRegression(solver = 'liblinear', max_iter = 500).fit(X_tfidf_train, y_train_arr)\n",
        "print('Log Regression\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "svc_tfidf = LinearSVC(C = 0.1, max_iter = 500).fit(X_tfidf_train, y_train_arr)\n",
        "print('SVC\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                  accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_test), y_true = y_test)))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d1178ad-934d-4a7d-ba8d-c2555ae958b1",
        "outputId": "1aa78294-1e94-46ed-9916-20087613fc03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of applying tuned hyperparameters\n",
            "-----------------------------------------\n",
            "Classifier\tTrain Acc.\tTest Acc.\n",
            "Naive Bayes\t 0.92994\t 0.73275\n",
            "SVM\t\t 0.81088\t 0.74700\n",
            "Log Regression\t 0.86787\t 0.75200\n",
            "SVC\t\t 0.86556\t 0.75350\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#WITHOUT TUNING\n",
        "\n",
        "# Logistic Regression\n",
        "m_lr = LogisticRegression()\n",
        "m_lr.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_lr_train = m_lr.predict(X_tfidf_train)\n",
        "y_pred_lr_test = m_lr.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "lr_train_accuracy = accuracy_score(y_train, y_pred_lr_train)\n",
        "lr_test_accuracy = accuracy_score(y_test, y_pred_lr_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Logistic Regression\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(lr_train_accuracy, lr_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr_test))\n",
        "\n",
        "\n",
        "\n",
        "# Linear SVC\n",
        "m_svc = LinearSVC()\n",
        "m_svc.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_svc_train = m_svc.predict(X_tfidf_train)\n",
        "y_pred_svc_test = m_svc.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svc_train_accuracy = accuracy_score(y_train, y_pred_svc_train)\n",
        "svc_test_accuracy = accuracy_score(y_test, y_pred_svc_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Linear SVC\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svc_train_accuracy, svc_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svc_test))\n",
        "\n",
        "\n",
        "\n",
        "# Support vector machine\n",
        "m_svm = SGDClassifier()\n",
        "m_svm.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_svm_train = m_svm.predict(X_tfidf_train)\n",
        "y_pred_svm_test = m_svm.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svm_train_accuracy = accuracy_score(y_train, y_pred_svm_train)\n",
        "svm_test_accuracy = accuracy_score(y_test, y_pred_svm_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Support Vector Machine\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svm_train_accuracy, svm_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_test))\n",
        "\n",
        "\n",
        "\n",
        "# naive bayes\n",
        "m_clf = MultinomialNB()\n",
        "m_clf.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_clf_train = m_clf.predict(X_tfidf_train)\n",
        "y_pred_clf_test = m_clf.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "clf_train_accuracy = accuracy_score(y_train, y_pred_clf_train)\n",
        "clf_test_accuracy = accuracy_score(y_test, y_pred_clf_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Naive Bayes\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(clf_train_accuracy, clf_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_clf_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SM2j1t2YbK8",
        "outputId": "0ef498c5-c4c9-47c1-ed4e-c4e0b5b97777"
      },
      "id": "2SM2j1t2YbK8",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\t Train Accuracy: 0.86675\t Test Accuracy: 0.75300\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.74      0.75      2021\n",
            "           1       0.74      0.77      0.76      1979\n",
            "\n",
            "    accuracy                           0.75      4000\n",
            "   macro avg       0.75      0.75      0.75      4000\n",
            "weighted avg       0.75      0.75      0.75      4000\n",
            "\n",
            "Linear SVC\t Train Accuracy: 0.97469\t Test Accuracy: 0.74475\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.74      0.75      2021\n",
            "           1       0.74      0.75      0.74      1979\n",
            "\n",
            "    accuracy                           0.74      4000\n",
            "   macro avg       0.74      0.74      0.74      4000\n",
            "weighted avg       0.74      0.74      0.74      4000\n",
            "\n",
            "Support Vector Machine\t Train Accuracy: 0.88581\t Test Accuracy: 0.75250\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.74      0.75      2021\n",
            "           1       0.74      0.77      0.75      1979\n",
            "\n",
            "    accuracy                           0.75      4000\n",
            "   macro avg       0.75      0.75      0.75      4000\n",
            "weighted avg       0.75      0.75      0.75      4000\n",
            "\n",
            "Naive Bayes\t Train Accuracy: 0.91394\t Test Accuracy: 0.74100\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76      2021\n",
            "           1       0.78      0.67      0.72      1979\n",
            "\n",
            "    accuracy                           0.74      4000\n",
            "   macro avg       0.75      0.74      0.74      4000\n",
            "weighted avg       0.75      0.74      0.74      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "id": "ac43490c-4d09-40d4-b8bf-7b4ce161eded",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#WITH TUNING\n",
        "\n",
        "\n",
        "# Logistic Regression\n",
        "# Predictions\n",
        "y_pred_lr_train = gs_lr.predict(X_tfidf_train)\n",
        "y_pred_lr_test = gs_lr.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "lr_train_accuracy = accuracy_score(y_train, y_pred_lr_train)\n",
        "lr_test_accuracy = accuracy_score(y_test, y_pred_lr_test)\n",
        "\n",
        "print (\"Logistic Regression\")\n",
        "for param_name in sorted(lr_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Logistic Regression\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(lr_train_accuracy, lr_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr_test))\n",
        "\n",
        "\n",
        "\n",
        "# Linear SVC\n",
        "# Predictions\n",
        "y_pred_svc_train = gs_svc.predict(X_tfidf_train)\n",
        "y_pred_svc_test = gs_svc.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svc_train_accuracy = accuracy_score(y_train, y_pred_svc_train)\n",
        "svc_test_accuracy = accuracy_score(y_test, y_pred_svc_test)\n",
        "\n",
        "print (\"Linear SVC\")\n",
        "for param_name in sorted(svc_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svc.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Linear SVC\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svc_train_accuracy, svc_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svc_test))\n",
        "\n",
        "\n",
        "\n",
        "# Support vector machine\n",
        "# Predictions\n",
        "y_pred_svm_train = gs_svm.predict(X_tfidf_train)\n",
        "y_pred_svm_test = gs_svm.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svm_train_accuracy = accuracy_score(y_train, y_pred_svm_train)\n",
        "svm_test_accuracy = accuracy_score(y_test, y_pred_svm_test)\n",
        "\n",
        "print(\"Support Vector Machine\")\n",
        "for param_name in sorted(svm_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Support Vector Machine\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svm_train_accuracy, svm_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_test))\n",
        "\n",
        "\n",
        "\n",
        "# naive bayes\n",
        "# Predictions\n",
        "y_pred_clf_train = gs_clf.predict(X_tfidf_train)\n",
        "y_pred_clf_test = gs_clf.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "clf_train_accuracy = accuracy_score(y_train, y_pred_clf_train)\n",
        "clf_test_accuracy = accuracy_score(y_test, y_pred_clf_test)\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "for param_name in sorted(clf_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Naive Bayes\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(clf_train_accuracy, clf_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_clf_test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ac43490c-4d09-40d4-b8bf-7b4ce161eded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f249316-6a02-4b3d-d14e-051e183704c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "max_iter: 500\n",
            "solver: 'liblinear'\n",
            "---------------------------------------------------------\n",
            "Logistic Regression\t Train Accuracy: 0.86787\t Test Accuracy: 0.75200\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.74      0.75      2021\n",
            "           1       0.74      0.77      0.75      1979\n",
            "\n",
            "    accuracy                           0.75      4000\n",
            "   macro avg       0.75      0.75      0.75      4000\n",
            "weighted avg       0.75      0.75      0.75      4000\n",
            "\n",
            "Linear SVC\n",
            "C: 0.1\n",
            "max_iter: 500\n",
            "---------------------------------------------------------\n",
            "Linear SVC\t Train Accuracy: 0.86556\t Test Accuracy: 0.75350\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.73      0.75      2021\n",
            "           1       0.74      0.78      0.76      1979\n",
            "\n",
            "    accuracy                           0.75      4000\n",
            "   macro avg       0.75      0.75      0.75      4000\n",
            "weighted avg       0.75      0.75      0.75      4000\n",
            "\n",
            "Support Vector Machine\n",
            "alpha: 0.001\n",
            "loss: 'squared_error'\n",
            "max_iter: 1000\n",
            "---------------------------------------------------------\n",
            "Support Vector Machine\t Train Accuracy: 0.81112\t Test Accuracy: 0.74775\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.72      0.74      2021\n",
            "           1       0.73      0.78      0.75      1979\n",
            "\n",
            "    accuracy                           0.75      4000\n",
            "   macro avg       0.75      0.75      0.75      4000\n",
            "weighted avg       0.75      0.75      0.75      4000\n",
            "\n",
            "Naive Bayes\n",
            "alpha: 1.0\n",
            "fit_prior: True\n",
            "force_alpha: True\n",
            "---------------------------------------------------------\n",
            "Naive Bayes\t Train Accuracy: 0.91394\t Test Accuracy: 0.74100\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76      2021\n",
            "           1       0.78      0.67      0.72      1979\n",
            "\n",
            "    accuracy                           0.74      4000\n",
            "   macro avg       0.75      0.74      0.74      4000\n",
            "weighted avg       0.75      0.74      0.74      4000\n",
            "\n"
          ]
        }
      ],
      "execution_count": 14
    }
  ]
}