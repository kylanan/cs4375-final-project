{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9736061e-acd8-482b-b93e-402826461332",
      "cell_type": "code",
      "source": [
        "%pip install -q kagglehub\n",
        "print('done')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9736061e-acd8-482b-b93e-402826461332",
        "outputId": "d8038021-e47b-4850-93a3-d581f9584be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import amazon_dataset\n",
        "X, y = amazon_dataset.load_amazon_reviews()\n",
        "\n",
        "X = X.sample(n = 20000, random_state=1)\n",
        "y = y.sample(n = 20000, random_state=1)\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMWJA3apR1bu",
        "outputId": "6f25bef2-0a63-4e58-cde4-ef47ed61b751"
      },
      "id": "VMWJA3apR1bu",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Amazon Fine Food Reviews dataset from Kaggle...\n",
            "Dataset downloaded to: /kaggle/input/amazon-fine-food-reviews\n",
            "Loading data from /kaggle/input/amazon-fine-food-reviews/Reviews.csv...\n",
            "Original dataset shape: (568454, 10)\n",
            "Shape after filtering out neutral reviews (Score=3): (525814, 10)\n",
            "Data processing complete. Returning text reviews and binary sentiment labels.\n",
            "87500     This is one of my favorite flavors.  This Fren...\n",
            "476116    I bought this for my girl friend that recently...\n",
            "225031    Not a big fan of chili actually... so these al...\n",
            "155722    The tea helped me tremendously with getting a ...\n",
            "55081     I use curry powder in a lot of my cooking - fr...\n",
            "                                ...                        \n",
            "227313    My son is on a very restricted diet, and this ...\n",
            "400922    I like cats.  I like dogs.  I just don't like ...\n",
            "45510     I was not sure what to expect with this drink ...\n",
            "208236    I was surprised that these were flavored so po...\n",
            "91683     The title says it all!!<br /><br />If you pay ...\n",
            "Name: Text, Length: 20000, dtype: object\n",
            "87500     1\n",
            "476116    1\n",
            "225031    1\n",
            "155722    1\n",
            "55081     1\n",
            "         ..\n",
            "227313    1\n",
            "400922    1\n",
            "45510     1\n",
            "208236    0\n",
            "91683     1\n",
            "Name: Sentiment, Length: 20000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "id": "e82a9506-206c-4071-9bcc-bc17f56b5d0b",
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "#import dataset\n",
        "#data = pd.read_csv(\"RateMyProfessor_Sample data.csv\", usecols = [\"comments\", \"student_star\"])\n",
        "\n",
        "\n",
        "#preprocessing\n",
        "#remove all punctuation\n",
        "X = X.str.replace(r'[^\\w\\s]+', '', regex = True)\n",
        "#make all letters lowercase\n",
        "X = X.str.lower()\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82a9506-206c-4071-9bcc-bc17f56b5d0b",
        "outputId": "4b62ed1c-75f8-4c29-f1e3-a0cf4b04fc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87500     this is one of my favorite flavors  this frenc...\n",
            "476116    i bought this for my girl friend that recently...\n",
            "225031    not a big fan of chili actually so these almon...\n",
            "155722    the tea helped me tremendously with getting a ...\n",
            "55081     i use curry powder in a lot of my cooking  fro...\n",
            "                                ...                        \n",
            "227313    my son is on a very restricted diet and this c...\n",
            "400922    i like cats  i like dogs  i just dont like my ...\n",
            "45510     i was not sure what to expect with this drink ...\n",
            "208236    i was surprised that these were flavored so po...\n",
            "91683     the title says it allbr br if you pay less you...\n",
            "Name: Text, Length: 20000, dtype: object\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "id": "54675cbf-331c-4420-91ce-cc34e578062b",
      "cell_type": "code",
      "source": [
        "#feature extraction\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#list of stop words\n",
        "stop_str = (['the', 'a', 'and', 'to', 'you', 'is', 'he', 'she', 'of', 'an', 'in',\n",
        "            'but', 'his', 'her', 'was', 'have', 'with', 'take', 'with', 'that', 'do', 'be',\n",
        "            'for', 'if', 'it', 'are', 'on', 'this', 'will', 'at', 'about', 'as', 'so', 'guy',\n",
        "            'him', 'your', 'had', 'can', 'hes', 'from', 'me', 'its', 'shes', 'get', 'my'])\n",
        "\n",
        "cv = CountVectorizer(stop_words = stop_str)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "\n",
        "#bag of words\n",
        "X_bow = cv.fit_transform(X.values.astype('U'))\n",
        "X_bow.shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54675cbf-331c-4420-91ce-cc34e578062b",
        "outputId": "d4298d3f-915c-44cc-bde8-27aa5c6c31b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 40147)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "id": "9c2f15e8-4676-4cbe-91e8-8b65dd77a477",
      "cell_type": "code",
      "source": [
        "#analysis of dataset\n",
        "#class distribution, text length distribution, total unique words, most common words\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print('The accuracy for Naive Bayes classifier using TF-IDF is {:.5f} on training data'.format(accuracy_score(y_pred = clf.predict(X_train), y_true = y_train)))\n",
        "#pos_ct = sum(data['student_star'] > 0)\n",
        "pos_ct = sum(y > 0)\n",
        "#neg_ct = sum(data['student_star'] < 0)\n",
        "neg_ct = sum(y == 0)\n",
        "\n",
        "print('There are {:.0f} total records.'.format( pos_ct + neg_ct ))\n",
        "print('There are {:.0f} positive records.'.format( pos_ct ))\n",
        "print('There are {:.0f} negative records.'.format( neg_ct ))\n",
        "print('{:.2f}% of records in the dataset are positive.\\n'.format( (pos_ct / (pos_ct + neg_ct)) * 100 ))\n",
        "\n",
        "'''\n",
        "word_ct = pd.read_csv(\"RateMyProfessor_Sample data.csv\", usecols = [\"word_comment\"])\n",
        "plt.hist(word_ct, color='lightgreen', ec='black', bins=10)\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Word Count\")\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "print('\\nThere are {:.0f} unique words.\\n'.format( len(cv.get_feature_names_out()) ))\n",
        "\n",
        "print('The 25 most common words, excluding stop words, are: ')\n",
        "freqs = zip(cv.get_feature_names_out(), X_bow.sum(axis=0).tolist()[0])\n",
        "# sort from largest to smallest\n",
        "print( sorted(freqs, key=lambda x: -x[1]) [:25])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2f15e8-4676-4cbe-91e8-8b65dd77a477",
        "outputId": "bbc76a58-de73-4ae9-9370-9cf414991242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 20000 total records.\n",
            "There are 16822 positive records.\n",
            "There are 3178 negative records.\n",
            "84.11% of records in the dataset are positive.\n",
            "\n",
            "\n",
            "There are 40147 unique words.\n",
            "\n",
            "The 25 most common words, excluding stop words, are: \n",
            "[('not', 10960), ('they', 9701), ('br', 9161), ('like', 8772), ('these', 8270), ('them', 7303), ('good', 6660), ('or', 6084), ('one', 6026), ('great', 5992), ('just', 5925), ('very', 5844), ('taste', 5639), ('all', 5592), ('coffee', 5427), ('product', 5098), ('we', 4952), ('when', 4788), ('flavor', 4773), ('tea', 4690), ('love', 4606), ('has', 4566), ('more', 4462), ('food', 4195), ('would', 4039)]\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "id": "b65ed94f-2062-48e0-99b8-68f5e18fbf74",
      "cell_type": "code",
      "source": [
        "#training classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train-test split with Bag of Words, then apply TF-IDF to have same set of sample data\n",
        "X_bow_train, X_bow_test, y_train, y_test = train_test_split(X_bow, y, test_size = 0.2)\n",
        "\n",
        "y_train_arr = y_train.to_numpy().reshape(-1)\n",
        "\n",
        "X_tfidf_train = tfidf_transformer.fit_transform(X_bow_train)\n",
        "X_tfidf_train.shape\n",
        "X_tfidf_test = tfidf_transformer.fit_transform(X_bow_test)\n",
        "X_tfidf_test.shape\n",
        "\n",
        "print('Classifier\\t Feature Extr.\\t Train Acc.\\t Test Acc.')\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "#naive bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf_bow = MultinomialNB().fit(X_bow_train, y_train_arr)\n",
        "clf_tfidf = MultinomialNB().fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                                              accuracy_score(y_pred = clf_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('Naive Bayes\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                                 accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#support vector machine\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "svm_bow = SGDClassifier().fit(X_bow_train, y_train_arr)\n",
        "svm_tfidf = SGDClassifier().fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM\\t\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                                          accuracy_score(y_pred = svm_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('SVM\\t\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                             accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_bow = LogisticRegression().fit(X_bow_train, y_train_arr)\n",
        "lr_tfidf = LogisticRegression().fit(X_tfidf_train, y_train_arr)\n",
        "print('Log Regression\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('Log Regression\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_bow.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#linear support vector classification\n",
        "from sklearn.svm import LinearSVC\n",
        "svc_bow = LinearSVC(max_iter = 2000).fit(X_bow_train, y_train_arr)\n",
        "svc_tfidf = LinearSVC().fit(X_tfidf_train, y_train_arr)\n",
        "print('SVC\\t\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = svc_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('SVC\\t\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                  accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b65ed94f-2062-48e0-99b8-68f5e18fbf74",
        "outputId": "f2bfbf7b-3488-41d8-9d28-bc662bf95570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier\t Feature Extr.\t Train Acc.\t Test Acc.\n",
            "---------------------------------------------------------\n",
            "Naive Bayes\t BoW\t\t 0.93506\t 0.88775\n",
            "Naive Bayes\t TF-IDF\t\t 0.84075\t 0.84300\n",
            "---------------------------------------------------------\n",
            "SVM\t\t BoW\t\t 0.99550\t 0.90450\n",
            "SVM\t\t TF-IDF\t\t 0.94812\t 0.90950\n",
            "---------------------------------------------------------\n",
            "Log Regression\t BoW\t\t 0.99138\t 0.91275\n",
            "Log Regression\t TF-IDF\t\t 0.92263\t 0.85100\n",
            "---------------------------------------------------------\n",
            "SVC\t\t BoW\t\t 0.99975\t 0.90100\n",
            "SVC\t\t TF-IDF\t\t 0.99056\t 0.91500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "id": "1149fbcb-566c-4e5b-ab30-5273ae03764f",
      "cell_type": "code",
      "source": [
        "#hyperparameter testing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "print('Testing for hyperparameters:')\n",
        "\n",
        "#naive bayes\n",
        "clf_param = {\n",
        "    'fit_prior': (True, False),\n",
        "    'force_alpha': (True, False),\n",
        "    'alpha': (1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1),\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(clf_tfidf, clf_param, cv=5, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes:')\n",
        "for param_name in sorted(clf_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#support vector machine\n",
        "svm_param = {\n",
        "    'max_iter': (1500, 1000, 500),\n",
        "    'loss': ('hinge', 'perceptron', 'squared_error'),\n",
        "    'alpha': (0.01, 0.005, 0.001),\n",
        "}\n",
        "\n",
        "gs_svm = GridSearchCV(svm_tfidf, svm_param, cv=5, n_jobs=-1)\n",
        "gs_svm = gs_svm.fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM:')\n",
        "for param_name in sorted(svm_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#logistic regression\n",
        "lr_param = {\n",
        "    'solver': ('lbfgs', 'liblinear', 'newton-cg'),\n",
        "    'max_iter': (500, 750, 1000, 1250)\n",
        "}\n",
        "\n",
        "gs_lr = GridSearchCV(lr_tfidf, lr_param, cv=5, n_jobs=-1)\n",
        "gs_lr = gs_lr.fit(X_tfidf_train, y_train_arr)\n",
        "print('Logistic Regression:')\n",
        "for param_name in sorted(lr_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#linear support vector classification\n",
        "svc_param = {\n",
        "    'max_iter': (500, 750, 1000, 2000, 2500),\n",
        "    'C': (0.01, 0.1, 0.5, 1.0, 1.5),\n",
        "}\n",
        "\n",
        "gs_svc = GridSearchCV(svc_tfidf, svc_param, cv=5, n_jobs=-1)\n",
        "gs_svc = gs_svc.fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM:')\n",
        "for param_name in sorted(svc_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svc.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1149fbcb-566c-4e5b-ab30-5273ae03764f",
        "outputId": "0fca4bfb-08ee-4e39-d46d-0c810e9ff8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for hyperparameters:\n",
            "Naive Bayes:\n",
            "alpha: 0.2\n",
            "fit_prior: False\n",
            "force_alpha: True\n",
            "---------------------------------------------------------\n",
            "SVM:\n",
            "alpha: 0.005\n",
            "loss: 'perceptron'\n",
            "max_iter: 500\n",
            "---------------------------------------------------------\n",
            "Logistic Regression:\n",
            "max_iter: 500\n",
            "solver: 'lbfgs'\n",
            "---------------------------------------------------------\n",
            "SVM:\n",
            "C: 1.0\n",
            "max_iter: 500\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "id": "3d1178ad-934d-4a7d-ba8d-c2555ae958b1",
      "cell_type": "code",
      "source": [
        "#testing the optimized hyperparameters with TF-IDF\n",
        "print('Results of applying tuned hyperparameters')\n",
        "print('-----------------------------------------')\n",
        "\n",
        "print('Classifier\\tTrain Acc.\\tTest Acc.')\n",
        "clf_tfidf = MultinomialNB(alpha = 0.6).fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                                 accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "svm_tfidf = SGDClassifier(alpha = 0.001, loss = 'squared_error', max_iter = 1500).fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                             accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "lr_tfidf = LogisticRegression(solver = 'liblinear', max_iter = 500).fit(X_tfidf_train, y_train_arr)\n",
        "print('Log Regression\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_bow.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "svc_tfidf = LinearSVC(C = 0.1, max_iter = 500).fit(X_tfidf_train, y_train_arr)\n",
        "print('SVC\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                  accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_test), y_true = y_test)))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d1178ad-934d-4a7d-ba8d-c2555ae958b1",
        "outputId": "d128ba62-02a5-4c35-da0d-f135026b5cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of applying tuned hyperparameters\n",
            "-----------------------------------------\n",
            "Classifier\tTrain Acc.\tTest Acc.\n",
            "Naive Bayes\t 0.84481\t 0.84275\n",
            "SVM\t\t 0.86769\t 0.86425\n",
            "Log Regression\t 0.92306\t 0.85100\n",
            "SVC\t\t 0.92375\t 0.90000\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "id": "ac43490c-4d09-40d4-b8bf-7b4ce161eded",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ac43490c-4d09-40d4-b8bf-7b4ce161eded"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}