{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9736061e-acd8-482b-b93e-402826461332",
      "cell_type": "code",
      "source": [
        "%pip install -q kagglehub\n",
        "print('done')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9736061e-acd8-482b-b93e-402826461332",
        "outputId": "440ad5d0-2f24-4698-f359-ed03b6e6f29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import amazon_dataset\n",
        "X, y = amazon_dataset.load_amazon_reviews()\n",
        "\n",
        "X = X.sample(n = 20000, random_state=1)\n",
        "y = y.sample(n = 20000, random_state=1)\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMWJA3apR1bu",
        "outputId": "c42b2ee7-077f-45c6-8feb-4fb5075ba7d5"
      },
      "id": "VMWJA3apR1bu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Amazon Fine Food Reviews dataset from Kaggle...\n",
            "Dataset downloaded to: /kaggle/input/amazon-fine-food-reviews\n",
            "Loading data from /kaggle/input/amazon-fine-food-reviews/Reviews.csv...\n",
            "Original dataset shape: (568454, 10)\n",
            "Shape after filtering out neutral reviews (Score=3): (525814, 10)\n",
            "Data processing complete. Returning text reviews and binary sentiment labels.\n",
            "87500     This is one of my favorite flavors.  This Fren...\n",
            "476116    I bought this for my girl friend that recently...\n",
            "225031    Not a big fan of chili actually... so these al...\n",
            "155722    The tea helped me tremendously with getting a ...\n",
            "55081     I use curry powder in a lot of my cooking - fr...\n",
            "                                ...                        \n",
            "227313    My son is on a very restricted diet, and this ...\n",
            "400922    I like cats.  I like dogs.  I just don't like ...\n",
            "45510     I was not sure what to expect with this drink ...\n",
            "208236    I was surprised that these were flavored so po...\n",
            "91683     The title says it all!!<br /><br />If you pay ...\n",
            "Name: Text, Length: 20000, dtype: object\n",
            "87500     1\n",
            "476116    1\n",
            "225031    1\n",
            "155722    1\n",
            "55081     1\n",
            "         ..\n",
            "227313    1\n",
            "400922    1\n",
            "45510     1\n",
            "208236    0\n",
            "91683     1\n",
            "Name: Sentiment, Length: 20000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "id": "e82a9506-206c-4071-9bcc-bc17f56b5d0b",
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "#import dataset\n",
        "#data = pd.read_csv(\"RateMyProfessor_Sample data.csv\", usecols = [\"comments\", \"student_star\"])\n",
        "\n",
        "\n",
        "#preprocessing\n",
        "#remove all punctuation\n",
        "X = X.str.replace(r'[^\\w\\s]+', '', regex = True)\n",
        "#make all letters lowercase\n",
        "X = X.str.lower()\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82a9506-206c-4071-9bcc-bc17f56b5d0b",
        "outputId": "151c8ba6-3a25-4a13-dce0-32de68e2c2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87500     this is one of my favorite flavors  this frenc...\n",
            "476116    i bought this for my girl friend that recently...\n",
            "225031    not a big fan of chili actually so these almon...\n",
            "155722    the tea helped me tremendously with getting a ...\n",
            "55081     i use curry powder in a lot of my cooking  fro...\n",
            "                                ...                        \n",
            "227313    my son is on a very restricted diet and this c...\n",
            "400922    i like cats  i like dogs  i just dont like my ...\n",
            "45510     i was not sure what to expect with this drink ...\n",
            "208236    i was surprised that these were flavored so po...\n",
            "91683     the title says it allbr br if you pay less you...\n",
            "Name: Text, Length: 20000, dtype: object\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "id": "54675cbf-331c-4420-91ce-cc34e578062b",
      "cell_type": "code",
      "source": [
        "#feature extraction\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#list of stop words\n",
        "stop_str = (['the', 'a', 'and', 'to', 'you', 'is', 'he', 'she', 'of', 'an', 'in',\n",
        "            'but', 'his', 'her', 'was', 'have', 'with', 'take', 'with', 'that', 'do', 'be',\n",
        "            'for', 'if', 'it', 'are', 'on', 'this', 'will', 'at', 'about', 'as', 'so', 'guy',\n",
        "            'him', 'your', 'had', 'can', 'hes', 'from', 'me', 'its', 'shes', 'get', 'my'])\n",
        "\n",
        "cv = CountVectorizer(stop_words = stop_str)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "\n",
        "#bag of words\n",
        "X_bow = cv.fit_transform(X.values.astype('U'))\n",
        "X_bow.shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54675cbf-331c-4420-91ce-cc34e578062b",
        "outputId": "4e1b91f7-9afd-4cd3-e577-a389a0980754"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 40147)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "id": "9c2f15e8-4676-4cbe-91e8-8b65dd77a477",
      "cell_type": "code",
      "source": [
        "#analysis of dataset\n",
        "#class distribution, text length distribution, total unique words, most common words\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print('The accuracy for Naive Bayes classifier using TF-IDF is {:.5f} on training data'.format(accuracy_score(y_pred = clf.predict(X_train), y_true = y_train)))\n",
        "#pos_ct = sum(data['student_star'] > 0)\n",
        "pos_ct = sum(y > 0)\n",
        "#neg_ct = sum(data['student_star'] < 0)\n",
        "neg_ct = sum(y == 0)\n",
        "\n",
        "print('There are {:.0f} total records.'.format( pos_ct + neg_ct ))\n",
        "print('There are {:.0f} positive records.'.format( pos_ct ))\n",
        "print('There are {:.0f} negative records.'.format( neg_ct ))\n",
        "print('{:.2f}% of records in the dataset are positive.\\n'.format( (pos_ct / (pos_ct + neg_ct)) * 100 ))\n",
        "\n",
        "'''\n",
        "word_ct = pd.read_csv(\"RateMyProfessor_Sample data.csv\", usecols = [\"word_comment\"])\n",
        "plt.hist(word_ct, color='lightgreen', ec='black', bins=10)\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Word Count\")\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "print('\\nThere are {:.0f} unique words.\\n'.format( len(cv.get_feature_names_out()) ))\n",
        "\n",
        "print('The 25 most common words, excluding stop words, are: ')\n",
        "freqs = zip(cv.get_feature_names_out(), X_bow.sum(axis=0).tolist()[0])\n",
        "# sort from largest to smallest\n",
        "print( sorted(freqs, key=lambda x: -x[1]) [:25])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2f15e8-4676-4cbe-91e8-8b65dd77a477",
        "outputId": "3640b732-a238-4e39-fb3e-155afb8e4cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 20000 total records.\n",
            "There are 16822 positive records.\n",
            "There are 3178 negative records.\n",
            "84.11% of records in the dataset are positive.\n",
            "\n",
            "\n",
            "There are 40147 unique words.\n",
            "\n",
            "The 25 most common words, excluding stop words, are: \n",
            "[('not', 10960), ('they', 9701), ('br', 9161), ('like', 8772), ('these', 8270), ('them', 7303), ('good', 6660), ('or', 6084), ('one', 6026), ('great', 5992), ('just', 5925), ('very', 5844), ('taste', 5639), ('all', 5592), ('coffee', 5427), ('product', 5098), ('we', 4952), ('when', 4788), ('flavor', 4773), ('tea', 4690), ('love', 4606), ('has', 4566), ('more', 4462), ('food', 4195), ('would', 4039)]\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "id": "b65ed94f-2062-48e0-99b8-68f5e18fbf74",
      "cell_type": "code",
      "source": [
        "#training classifiers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train-test split with Bag of Words, then apply TF-IDF to have same set of sample data\n",
        "X_bow_train, X_bow_test, y_train, y_test = train_test_split(X_bow, y, test_size = 0.2)\n",
        "\n",
        "y_train_arr = y_train.to_numpy().reshape(-1)\n",
        "\n",
        "X_tfidf_train = tfidf_transformer.fit_transform(X_bow_train)\n",
        "X_tfidf_train.shape\n",
        "X_tfidf_test = tfidf_transformer.fit_transform(X_bow_test)\n",
        "X_tfidf_test.shape\n",
        "\n",
        "print('Classifier\\t Feature Extr.\\t Train Acc.\\t Test Acc.')\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "#naive bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf_bow = MultinomialNB().fit(X_bow_train, y_train_arr)\n",
        "clf_tfidf = MultinomialNB().fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                                              accuracy_score(y_pred = clf_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('Naive Bayes\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                                 accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#support vector machine\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "svm_bow = SGDClassifier().fit(X_bow_train, y_train_arr)\n",
        "svm_tfidf = SGDClassifier().fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM\\t\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                                          accuracy_score(y_pred = svm_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('SVM\\t\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                             accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_bow = LogisticRegression().fit(X_bow_train, y_train_arr)\n",
        "lr_tfidf = LogisticRegression().fit(X_tfidf_train, y_train_arr)\n",
        "print('Log Regression\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('Log Regression\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "print('---------------------------------------------------------')\n",
        "#linear support vector classification\n",
        "from sklearn.svm import LinearSVC\n",
        "svc_bow = LinearSVC(max_iter = 2000).fit(X_bow_train, y_train_arr)\n",
        "svc_tfidf = LinearSVC().fit(X_tfidf_train, y_train_arr)\n",
        "print('SVC\\t\\t BoW\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_bow.predict(X_bow_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = svc_bow.predict(X_bow_test), y_true = y_test)))\n",
        "print('SVC\\t\\t TF-IDF\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                  accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b65ed94f-2062-48e0-99b8-68f5e18fbf74",
        "outputId": "630eb6e6-5760-4512-d45d-bdc841b1ea42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier\t Feature Extr.\t Train Acc.\t Test Acc.\n",
            "---------------------------------------------------------\n",
            "Naive Bayes\t BoW\t\t 0.93650\t 0.88800\n",
            "Naive Bayes\t TF-IDF\t\t 0.84088\t 0.84275\n",
            "---------------------------------------------------------\n",
            "SVM\t\t BoW\t\t 0.99600\t 0.90250\n",
            "SVM\t\t TF-IDF\t\t 0.94881\t 0.90850\n",
            "---------------------------------------------------------\n",
            "Log Regression\t BoW\t\t 0.99187\t 0.90950\n",
            "Log Regression\t TF-IDF\t\t 0.92344\t 0.90200\n",
            "---------------------------------------------------------\n",
            "SVC\t\t BoW\t\t 0.99981\t 0.89700\n",
            "SVC\t\t TF-IDF\t\t 0.99150\t 0.91750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "id": "1149fbcb-566c-4e5b-ab30-5273ae03764f",
      "cell_type": "code",
      "source": [
        "#hyperparameter testing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "print('Testing for hyperparameters:')\n",
        "\n",
        "#naive bayes\n",
        "clf_param = {\n",
        "    'fit_prior': (True, False),\n",
        "    'force_alpha': (True, False),\n",
        "    'alpha': (1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1),\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(clf_tfidf, clf_param, cv=5, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes:')\n",
        "for param_name in sorted(clf_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#support vector machine\n",
        "svm_param = {\n",
        "    'max_iter': (1500, 1000, 500),\n",
        "    'loss': ('hinge', 'perceptron', 'squared_error'),\n",
        "    'alpha': (0.01, 0.005, 0.001),\n",
        "}\n",
        "\n",
        "gs_svm = GridSearchCV(svm_tfidf, svm_param, cv=5, n_jobs=-1)\n",
        "gs_svm = gs_svm.fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM:')\n",
        "for param_name in sorted(svm_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#logistic regression\n",
        "lr_param = {\n",
        "    'solver': ('lbfgs', 'liblinear', 'newton-cg'),\n",
        "    'max_iter': (500, 750, 1000, 1250)\n",
        "}\n",
        "\n",
        "gs_lr = GridSearchCV(lr_tfidf, lr_param, cv=5, n_jobs=-1)\n",
        "gs_lr = gs_lr.fit(X_tfidf_train, y_train_arr)\n",
        "print('Logistic Regression:')\n",
        "for param_name in sorted(lr_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "#linear support vector classification\n",
        "svc_param = {\n",
        "    'max_iter': (500, 750, 1000, 2000, 2500),\n",
        "    'C': (0.01, 0.1, 0.5, 1.0, 1.5),\n",
        "}\n",
        "\n",
        "gs_svc = GridSearchCV(svc_tfidf, svc_param, cv=5, n_jobs=-1)\n",
        "gs_svc = gs_svc.fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM:')\n",
        "for param_name in sorted(svc_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svc.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1149fbcb-566c-4e5b-ab30-5273ae03764f",
        "outputId": "4615ec7e-8407-4469-b97f-fda0982e67cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for hyperparameters:\n",
            "Naive Bayes:\n",
            "alpha: 0.2\n",
            "fit_prior: False\n",
            "force_alpha: True\n",
            "---------------------------------------------------------\n",
            "SVM:\n",
            "alpha: 0.005\n",
            "loss: 'perceptron'\n",
            "max_iter: 1500\n",
            "---------------------------------------------------------\n",
            "Logistic Regression:\n",
            "max_iter: 500\n",
            "solver: 'lbfgs'\n",
            "---------------------------------------------------------\n",
            "SVM:\n",
            "C: 1.0\n",
            "max_iter: 500\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "id": "3d1178ad-934d-4a7d-ba8d-c2555ae958b1",
      "cell_type": "code",
      "source": [
        "#testing the optimized hyperparameters with TF-IDF\n",
        "print('Results of applying tuned hyperparameters')\n",
        "print('-----------------------------------------')\n",
        "\n",
        "print('Classifier\\tTrain Acc.\\tTest Acc.')\n",
        "clf_tfidf = MultinomialNB(alpha = 0.6).fit(X_tfidf_train, y_train_arr)\n",
        "print('Naive Bayes\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                                 accuracy_score(y_pred = clf_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "svm_tfidf = SGDClassifier(alpha = 0.001, loss = 'squared_error', max_iter = 1500).fit(X_tfidf_train, y_train_arr)\n",
        "print('SVM\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                             accuracy_score(y_pred = svm_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "lr_tfidf = LogisticRegression(solver = 'liblinear', max_iter = 500).fit(X_tfidf_train, y_train_arr)\n",
        "print('Log Regression\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                               accuracy_score(y_pred = lr_tfidf.predict(X_tfidf_test), y_true = y_test)))\n",
        "\n",
        "svc_tfidf = LinearSVC(C = 0.1, max_iter = 500).fit(X_tfidf_train, y_train_arr)\n",
        "print('SVC\\t\\t {:.5f}\\t {:.5f}'.format(accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_train), y_true = y_train),\n",
        "                                                  accuracy_score(y_pred = svc_tfidf.predict(X_tfidf_test), y_true = y_test)))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d1178ad-934d-4a7d-ba8d-c2555ae958b1",
        "outputId": "870bff0e-ce24-4d6c-f2bb-026d4c768aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of applying tuned hyperparameters\n",
            "-----------------------------------------\n",
            "Classifier\tTrain Acc.\tTest Acc.\n",
            "Naive Bayes\t 0.84506\t 0.84300\n",
            "SVM\t\t 0.86638\t 0.86850\n",
            "Log Regression\t 0.92344\t 0.90200\n",
            "SVC\t\t 0.92375\t 0.90275\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#WITHOUT TUNING\n",
        "\n",
        "# Logistic Regression\n",
        "m_lr = LogisticRegression()\n",
        "m_lr.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_lr_train = m_lr.predict(X_tfidf_train)\n",
        "y_pred_lr_test = m_lr.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "lr_train_accuracy = accuracy_score(y_train, y_pred_lr_train)\n",
        "lr_test_accuracy = accuracy_score(y_test, y_pred_lr_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Logistic Regression\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(lr_train_accuracy, lr_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr_test))\n",
        "\n",
        "\n",
        "\n",
        "# Linear SVC\n",
        "m_svc = LinearSVC()\n",
        "m_svc.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_svc_train = m_svc.predict(X_tfidf_train)\n",
        "y_pred_svc_test = m_svc.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svc_train_accuracy = accuracy_score(y_train, y_pred_svc_train)\n",
        "svc_test_accuracy = accuracy_score(y_test, y_pred_svc_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Linear SVC\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svc_train_accuracy, svc_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svc_test))\n",
        "\n",
        "\n",
        "\n",
        "# Support vector machine\n",
        "m_svm = SGDClassifier()\n",
        "m_svm.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_svm_train = m_svm.predict(X_tfidf_train)\n",
        "y_pred_svm_test = m_svm.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svm_train_accuracy = accuracy_score(y_train, y_pred_svm_train)\n",
        "svm_test_accuracy = accuracy_score(y_test, y_pred_svm_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Support Vector Machine\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svm_train_accuracy, svm_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_test))\n",
        "\n",
        "\n",
        "\n",
        "# naive bayes\n",
        "m_clf = MultinomialNB()\n",
        "m_clf.fit(X_tfidf_train, y_train)\n",
        "# Predictions\n",
        "y_pred_clf_train = m_clf.predict(X_tfidf_train)\n",
        "y_pred_clf_test = m_clf.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "clf_train_accuracy = accuracy_score(y_train, y_pred_clf_train)\n",
        "clf_test_accuracy = accuracy_score(y_test, y_pred_clf_test)\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Naive Bayes\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(clf_train_accuracy, clf_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_clf_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SM2j1t2YbK8",
        "outputId": "68a08db5-4826-417d-954c-fb4d08e52089"
      },
      "id": "2SM2j1t2YbK8",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\t Train Accuracy: 0.92344\t Test Accuracy: 0.90200\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.43      0.58       629\n",
            "           1       0.90      0.99      0.94      3371\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.89      0.71      0.76      4000\n",
            "weighted avg       0.90      0.90      0.89      4000\n",
            "\n",
            "Linear SVC\t Train Accuracy: 0.99150\t Test Accuracy: 0.91750\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.63      0.71       629\n",
            "           1       0.93      0.97      0.95      3371\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.87      0.80      0.83      4000\n",
            "weighted avg       0.91      0.92      0.91      4000\n",
            "\n",
            "Support Vector Machine\t Train Accuracy: 0.94819\t Test Accuracy: 0.90650\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.51      0.63       629\n",
            "           1       0.91      0.98      0.95      3371\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.87      0.74      0.79      4000\n",
            "weighted avg       0.90      0.91      0.90      4000\n",
            "\n",
            "Naive Bayes\t Train Accuracy: 0.84088\t Test Accuracy: 0.84275\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       629\n",
            "           1       0.84      1.00      0.91      3371\n",
            "\n",
            "    accuracy                           0.84      4000\n",
            "   macro avg       0.42      0.50      0.46      4000\n",
            "weighted avg       0.71      0.84      0.77      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "id": "ac43490c-4d09-40d4-b8bf-7b4ce161eded",
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#WITH TUNING\n",
        "\n",
        "\n",
        "# Logistic Regression\n",
        "# Predictions\n",
        "y_pred_lr_train = gs_lr.predict(X_tfidf_train)\n",
        "y_pred_lr_test = gs_lr.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "lr_train_accuracy = accuracy_score(y_train, y_pred_lr_train)\n",
        "lr_test_accuracy = accuracy_score(y_test, y_pred_lr_test)\n",
        "\n",
        "print (\"Logistic Regression\")\n",
        "for param_name in sorted(lr_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Logistic Regression\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(lr_train_accuracy, lr_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr_test))\n",
        "\n",
        "\n",
        "\n",
        "# Linear SVC\n",
        "# Predictions\n",
        "y_pred_svc_train = gs_svc.predict(X_tfidf_train)\n",
        "y_pred_svc_test = gs_svc.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svc_train_accuracy = accuracy_score(y_train, y_pred_svc_train)\n",
        "svc_test_accuracy = accuracy_score(y_test, y_pred_svc_test)\n",
        "\n",
        "print (\"Linear SVC\")\n",
        "for param_name in sorted(svc_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svc.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Linear SVC\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svc_train_accuracy, svc_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svc_test))\n",
        "\n",
        "\n",
        "\n",
        "# Support vector machine\n",
        "# Predictions\n",
        "y_pred_svm_train = gs_svm.predict(X_tfidf_train)\n",
        "y_pred_svm_test = gs_svm.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "svm_train_accuracy = accuracy_score(y_train, y_pred_svm_train)\n",
        "svm_test_accuracy = accuracy_score(y_test, y_pred_svm_test)\n",
        "\n",
        "print(\"Support Vector Machine\")\n",
        "for param_name in sorted(svm_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Support Vector Machine\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(svm_train_accuracy, svm_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_test))\n",
        "\n",
        "\n",
        "\n",
        "# naive bayes\n",
        "# Predictions\n",
        "y_pred_clf_train = gs_clf.predict(X_tfidf_train)\n",
        "y_pred_clf_test = gs_clf.predict(X_tfidf_test)\n",
        "\n",
        "# Accuracy scores\n",
        "clf_train_accuracy = accuracy_score(y_train, y_pred_clf_train)\n",
        "clf_test_accuracy = accuracy_score(y_test, y_pred_clf_test)\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "for param_name in sorted(clf_param.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
        "print('---------------------------------------------------------')\n",
        "\n",
        "# Print formatted output\n",
        "print(\"Naive Bayes\\t Train Accuracy: {:.5f}\\t Test Accuracy: {:.5f}\".format(clf_train_accuracy, clf_test_accuracy))\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_clf_test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ac43490c-4d09-40d4-b8bf-7b4ce161eded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df851c6-7ce9-4f86-e0ad-3b207e6aaa62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "max_iter: 500\n",
            "solver: 'lbfgs'\n",
            "---------------------------------------------------------\n",
            "Logistic Regression\t Train Accuracy: 0.91731\t Test Accuracy: 0.92025\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.52      0.67       629\n",
            "           1       0.92      0.99      0.95      3371\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.93      0.76      0.81      4000\n",
            "weighted avg       0.92      0.92      0.91      4000\n",
            "\n",
            "Linear SVC\n",
            "C: 1.0\n",
            "max_iter: 500\n",
            "---------------------------------------------------------\n",
            "Linear SVC\t Train Accuracy: 0.97637\t Test Accuracy: 0.97725\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.89      0.92       629\n",
            "           1       0.98      0.99      0.99      3371\n",
            "\n",
            "    accuracy                           0.98      4000\n",
            "   macro avg       0.97      0.94      0.96      4000\n",
            "weighted avg       0.98      0.98      0.98      4000\n",
            "\n",
            "Support Vector Machine\n",
            "alpha: 0.005\n",
            "loss: 'perceptron'\n",
            "max_iter: 1500\n",
            "---------------------------------------------------------\n",
            "Support Vector Machine\t Train Accuracy: 0.97313\t Test Accuracy: 0.97375\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.91       629\n",
            "           1       0.98      0.99      0.98      3371\n",
            "\n",
            "    accuracy                           0.97      4000\n",
            "   macro avg       0.96      0.94      0.95      4000\n",
            "weighted avg       0.97      0.97      0.97      4000\n",
            "\n",
            "Naive Bayes\n",
            "alpha: 0.2\n",
            "fit_prior: False\n",
            "force_alpha: True\n",
            "---------------------------------------------------------\n",
            "Naive Bayes\t Train Accuracy: 0.93506\t Test Accuracy: 0.93500\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.71      0.77       629\n",
            "           1       0.95      0.98      0.96      3371\n",
            "\n",
            "    accuracy                           0.94      4000\n",
            "   macro avg       0.90      0.84      0.87      4000\n",
            "weighted avg       0.93      0.94      0.93      4000\n",
            "\n"
          ]
        }
      ],
      "execution_count": 24
    }
  ]
}